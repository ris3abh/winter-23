{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "removed-outreach",
   "metadata": {},
   "source": [
    "## Text Vectorization\n",
    "\n",
    "Question: What is text vectorization?\n",
    "\n",
    "Answer: **The process to transform text data to numerical vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = '''dog bites man. man bites dog. dog eats meat. man eats food.'''\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-pavilion",
   "metadata": {},
   "source": [
    "## Bag of Word (BoW) or Term document matrices (TDM)\n",
    "\n",
    "- Bag-of-Words (BoW) or TDM is a matrix where its **rows are sentences** and its **columns are unique words** seen across all of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vertical-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = ['.']\n",
    "def count_words(sentence):\n",
    "    frequency = Counter()\n",
    "    for word in sentence:\n",
    "        if word.text not in stop_word:\n",
    "            frequency[word.text] += 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "sweet-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the 'master' set, keeps track of the words in all documents\n",
    "all_words = set()\n",
    "\n",
    "## store the word frequencies by book\n",
    "all_doc_frequencies = {}\n",
    "\n",
    "## loop over the sentences\n",
    "for j, sentence in enumerate(doc.sents):\n",
    "    frequency = count_words(sentence)\n",
    "    all_doc_frequencies[j] = frequency\n",
    "    doc_words = set(frequency.keys())\n",
    "    all_words = all_words.union(doc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "absent-huntington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Counter({'dog': 1, 'bites': 1, 'man': 1}),\n",
       " 1: Counter({'man': 1, 'bites': 1, 'dog': 1}),\n",
       " 2: Counter({'dog': 1, 'eats': 1, 'meat': 1}),\n",
       " 3: Counter({'man': 1, 'eats': 1, 'food': 1})}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "willing-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## create a matrix of zeros: (documents) x (words)\n",
    "TDM = np.zeros((len(all_doc_frequencies), len(all_words)))\n",
    "## fix a word ordering for the columns\n",
    "all_words = sorted(list(all_words))\n",
    "## loop over the (sorted) document numbers and (ordered) words; fill in matrix\n",
    "for i in all_doc_frequencies:\n",
    "    for j, word in enumerate(all_words):\n",
    "        TDM[i,j] = all_doc_frequencies[i][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "nervous-opportunity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bites', 'dog', 'eats', 'food', 'man', 'meat']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "infrared-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 1., 0.],\n",
       "       [1., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "smoking-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.index('food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "southwest-dublin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(TDM[:, all_words.index('food')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-composition",
   "metadata": {},
   "source": [
    "# TF in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "helpful-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = ['Dog bites man.', ' Man bites dog.', 'Dog eats meat.', 'Man eats food.']\n",
    "count_vect = CountVectorizer()\n",
    "tf_matrix = count_vect.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "necessary-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "median-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bites', 'dog', 'eats', 'food', 'man', 'meat']\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-registrar",
   "metadata": {},
   "source": [
    "## What is TF-IDF Vectorizer?\n",
    "\n",
    "- Word counts are a good starting point, but are very basic\n",
    "\n",
    "An alternative is to calculate word frequencies, and by far the most popular method is called TF-IDF. \n",
    "\n",
    "**Term Frequency (TF)**: This summarizes how often a given word appears within a document\n",
    "\n",
    "**Inverse Document Frequency (IDF)**: This downscales words that appear a lot across documents\n",
    "\n",
    "<img src=\"TFIDF.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "atlantic-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bites', 2)\n",
      "('dog', 3)\n",
      "('eats', 2)\n",
      "('food', 1)\n",
      "('man', 3)\n",
      "('meat', 1)\n"
     ]
    }
   ],
   "source": [
    "num_docs = TDM.shape[0]\n",
    "\n",
    "## start off with a zero matrix of size TDM\n",
    "TFIDF = np.zeros(TDM.shape)\n",
    "## loop over words\n",
    "for i, word in enumerate(all_words):\n",
    "    ## count docs containing the word\n",
    "    num_docs_containing_word = len([x for x in TDM[:,i] if x])\n",
    "    print((word, num_docs_containing_word))\n",
    "    ### computen the inverse document frequence of this word\n",
    "    IDF = -np.log((num_docs_containing_word + 1) /(num_docs + 1)) + 1\n",
    "    ## multiply this row by the IDF to transform it to TFIDF\n",
    "    TFIDF[:,i] = TDM[:,i]*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "italian-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "arabic-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51082562, 1.22314355, 0.        , 0.        , 1.22314355,\n",
       "        0.        ],\n",
       "       [1.51082562, 1.22314355, 0.        , 0.        , 1.22314355,\n",
       "        0.        ],\n",
       "       [0.        , 1.22314355, 1.51082562, 0.        , 0.        ,\n",
       "        1.91629073],\n",
       "       [0.        , 0.        , 1.51082562, 1.91629073, 1.22314355,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "floral-billy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.29668334, 2.29668334, 2.72962349, 2.72962349])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# norm of each row in TFIDF\n",
    "np.apply_along_axis(np.linalg.norm, 1, TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "arctic-multiple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65782931, 0.53256952, 0.        , 0.        , 0.53256952,\n",
       "        0.        ],\n",
       "       [0.65782931, 0.53256952, 0.        , 0.        , 0.53256952,\n",
       "        0.        ],\n",
       "       [0.        , 0.44809973, 0.55349232, 0.        , 0.        ,\n",
       "        0.70203482],\n",
       "       [0.        , 0.        , 0.55349232, 0.70203482, 0.44809973,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(TFIDF.shape[0]):\n",
    "    TFIDF[i, :] = TFIDF[i, :]/np.apply_along_axis(np.linalg.norm, 1, TFIDF)[i]\n",
    "TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-recovery",
   "metadata": {},
   "source": [
    "## TFIDF in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "encouraging-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "documents = ['Dog bites man.', ' Man bites dog.', 'Dog eats meat.', 'Man eats food.']\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vect.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "indoor-player",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65782931, 0.53256952, 0.        , 0.        , 0.53256952,\n",
       "        0.        ],\n",
       "       [0.65782931, 0.53256952, 0.        , 0.        , 0.53256952,\n",
       "        0.        ],\n",
       "       [0.        , 0.44809973, 0.55349232, 0.        , 0.        ,\n",
       "        0.70203482],\n",
       "       [0.        , 0.        , 0.55349232, 0.70203482, 0.44809973,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "binding-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bites', 'dog', 'eats', 'food', 'man', 'meat']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-architect",
   "metadata": {},
   "source": [
    "## Activity: Obtain the keywords from TF-IDF\n",
    "\n",
    "1- First obtain the TF-IDF matrix for given corpus\n",
    "\n",
    "2- Do column-wise addition\n",
    "\n",
    "3- Sort the score from highest to lowest\n",
    "\n",
    "4- Return the associated words based on step 3\n",
    "\n",
    "Hint: You can sort the value of a dictionary and return its associated key -> D = {'bright': 0.7, 'blue':0.86, 'sun' : 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dried-corruption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78528828 0.         0.         0.6191303  0.        ]\n",
      " [0.         0.70710678 0.         0.         0.70710678]\n",
      " [0.         0.53256952 0.         0.65782931 0.53256952]\n",
      " [0.         0.36626037 0.57381765 0.         0.73252075]]\n",
      "['blue', 'bright', 'shining', 'sky', 'sun']\n",
      "[('sun', 1.9721970507561841), ('bright', 1.605936677684143), ('sky', 1.27695960978985)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def keyword_sklearn(docs, k):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "    print(tfidf_matrix.toarray())\n",
    "    print(vectorizer.get_feature_names())\n",
    "    tfidf_scores = np.sum(tfidf_matrix, axis=0)\n",
    "    tfidf_scores = np.ravel(tfidf_scores)\n",
    "    return sorted(dict(zip(vectorizer.get_feature_names(), tfidf_scores)).items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "documents = ['The sky is blue', 'The sun is bright', 'The sun in the sky is bright', 'we can see the shining sun, the bright sun']\n",
    "\n",
    "print(keyword_sklearn(documents, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-click",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "- https://medium.com/analytics-vidhya/demonstrating-calculation-of-tf-idf-from-sklearn-4f9526e7e78b\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
