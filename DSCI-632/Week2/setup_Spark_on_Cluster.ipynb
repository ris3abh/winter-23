{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "associate-astrology",
   "metadata": {},
   "source": [
    "# Set up Apache Spark on a Multi-Node Cluster\n",
    "\n",
    "- Big data is meaningful when we can distribute the computations among resources\n",
    "\n",
    "- Spark is a fast and powerful framework that provides an API to perform massive distributed processing of resilient sets of data over computational resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-webster",
   "metadata": {},
   "source": [
    "## Spark Architecture\n",
    "\n",
    "\n",
    "<img src=\"Spark_Architecture.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "- A spark cluster has a single Master and any number of Slaves/Workers.\n",
    "\n",
    "- Master and Workers wil have their own IP addresses\n",
    "\n",
    "- Spark jobs will be distributed to the master and workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-savage",
   "metadata": {},
   "source": [
    "## Spark Web UI\n",
    "\n",
    "- With Spark UI, we know about master and worker nodes including their IPs, number of cores, memories, running application\n",
    "\n",
    "<img src=\"Spark_UI.png\" width=\"800\" height=\"800\">\n",
    "\n",
    "We can see have a master and two workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-funeral",
   "metadata": {},
   "source": [
    "## Dataproc pricing for having a cluster for Big Data \n",
    "\n",
    "- Pricing for Dataproc is $0.010 * # of vCPUs * hourly duration: https://cloud.google.com/dataproc/pricing\n",
    "    - As an example having a cluster with one master and 5 workers each having 4 cores, using them for two hours: `$0.01*(1+5)*4*2=$0.48`  \n",
    "\n",
    "- Pick Dataproc from the top list: https://cloud.google.com/products/calculator\n",
    "<img src=\"Dataproc_Pricing.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-angola",
   "metadata": {},
   "source": [
    "## Create a Spark cluster on Google Dataproc (optional)\n",
    "\n",
    "-  There are two ways to create and control a Spark cluster on Dataproc:\n",
    "\n",
    "    - Through a form in Google's web-based console\n",
    "    - or directly through gcloud, a.k.a. Google Cloud SDK\n",
    "    \n",
    "\n",
    "- Google Cloud Tutorial for Hadoop, Spark Multinode Cluster and DataProc: https://www.youtube.com/watch?v=6DD-vBdJJxk\n",
    "- Using PySpark on Dataproc Hadoop Cluster to process large CSV file: https://www.youtube.com/watch?v=Y6OXGc0mmYM&t=8s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
