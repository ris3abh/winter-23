{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.read.csv('titanic.csv',header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top rows of Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket   |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22.0|1    |0    |A/5 21171|7.25   |null |S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38.0|1    |0    |PC 17599 |71.2833|C85  |C       |\n",
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select specific columns of Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+\n",
      "|Survived|   Sex| Age|\n",
      "+--------+------+----+\n",
      "|       0|  male|22.0|\n",
      "|       1|female|38.0|\n",
      "|       1|female|26.0|\n",
      "|       1|female|35.0|\n",
      "|       0|  male|35.0|\n",
      "+--------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Survived', 'Sex', 'Age']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice based on condition of Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Sex']== 'female').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many null values we have for a specific column of Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Age'].isNotNull()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values of a column in Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Embarked|\n",
      "+--------+\n",
      "|       Q|\n",
      "|    null|\n",
      "|       C|\n",
      "|       S|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Embarked']).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts in Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  644|\n",
      "|       C|  168|\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Embarked').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar functionality of .values in Pandas in Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'C', 'S', 'S', 'S', 'Q', 'S', 'S', 'S', 'C']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_lst = df.select(['Embarked']).rdd.flatMap(lambda x:x).collect()\n",
    "embarked_lst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better Way\n",
    "embarked_lst = df.select(['Embarked']).rdd.map(lambda x:x[0]).collect()\n",
    "embarked_lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values for multiple columns in Pyspaark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Embarked='S', Sex='male'),\n",
       " Row(Embarked='C', Sex='female'),\n",
       " Row(Embarked='S', Sex='female'),\n",
       " Row(Embarked='S', Sex='female'),\n",
       " Row(Embarked='S', Sex='male')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['Embarked', 'Sex']).rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['S', 'male'],\n",
       " ['C', 'female'],\n",
       " ['S', 'female'],\n",
       " ['S', 'female'],\n",
       " ['S', 'male']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['Embarked', 'Sex']).rdd.map(lambda x: [x[0],x[1]]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+\n",
      "|         avg(Age)|min(Age)|max(Age)|\n",
      "+-----------------+--------+--------+\n",
      "|29.69911764705882|    0.42|    80.0|\n",
      "+-----------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, min, max\n",
    "\n",
    "df.select([mean('Age'), min('Age'), max('Age')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+\n",
      "|         avg(Age)|min(Age)|max(Age)|\n",
      "+-----------------+--------+--------+\n",
      "|30.72664459161148|    0.42|    80.0|\n",
      "+-----------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Sex']== 'male').select([mean('Age'), min('Age'), max('Age')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------+\n",
      "|          avg(Age)|min(Age)|max(Age)|\n",
      "+------------------+--------+--------+\n",
      "|27.915708812260537|    0.75|    63.0|\n",
      "+------------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Sex']== 'female').select([mean('Age'), min('Age'), max('Age')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, min, max\n",
    "\n",
    "# Average of Age for Male and Female in one line\n",
    "df.select(['Sex', 'Age']).groupby('Sex').agg(mean('Age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosstab in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---+\n",
      "|Sex_Survived|  0|  1|\n",
      "+------------+---+---+\n",
      "|        male|468|109|\n",
      "|      female| 81|233|\n",
      "+------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab('Sex', 'Survived').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+\n",
      "|Survived_Sex|female|male|\n",
      "+------------+------+----+\n",
      "|           1|   233| 109|\n",
      "|           0|    81| 468|\n",
      "+------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab('Survived', 'Sex').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Survived'] == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "233+109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: what percentage of female passengers survived?\n",
    "- Use Pyspark syntaxes to answer this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df['Sex']=='female') & (df['Survived'] == 1)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Sex']=='female').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "233+81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420382165605095"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "233/314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|   73|\n",
      "|  male|   95|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Embarked'] == 'C').groupby('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+\n",
      "|Embarked_Sex|female|male|\n",
      "+------------+------+----+\n",
      "|           S|   203| 441|\n",
      "|           C|    73|  95|\n",
      "|           Q|    36|  41|\n",
      "|        null|     2|   0|\n",
      "+------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.crosstab('Embarked', 'Sex').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|   Sex| Age|count|\n",
      "+------+----+-----+\n",
      "|  male|null|   26|\n",
      "|female|null|   12|\n",
      "|female|24.0|    5|\n",
      "|  male|30.0|    4|\n",
      "|  male|25.0|    4|\n",
      "|female|17.0|    3|\n",
      "|female|18.0|    3|\n",
      "|  male|40.0|    3|\n",
      "|  male|20.0|    3|\n",
      "|  male|49.0|    3|\n",
      "|female|30.0|    3|\n",
      "|  male|35.0|    3|\n",
      "|  male|27.0|    3|\n",
      "|  male|26.0|    3|\n",
      "|  male|36.0|    3|\n",
      "|  male|22.0|    3|\n",
      "|  male|58.0|    2|\n",
      "|female|44.0|    2|\n",
      "|female|14.0|    2|\n",
      "|  male|17.0|    2|\n",
      "+------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Embarked'] == 'C').groupby(['Sex', 'Age']).count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['female', 38.0],\n",
       " ['female', 14.0],\n",
       " ['female', None],\n",
       " ['male', None],\n",
       " ['male', 40.0]]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Embarked'] == 'C').select(['Sex', 'Age']).rdd.map(lambda x: [x[0],x[1]]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|   Sex|   collect_list(Age)|\n",
      "+------+--------------------+\n",
      "|female|[38.0, 14.0, 14.0...|\n",
      "|  male|[40.0, 28.0, 65.0...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.filter(df['Embarked'] == 'C').select(['Sex', 'Age']).groupby('Sex').agg(F.collect_list('Age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: How many female and male do we have in Titanic?\n",
    "\n",
    "- Pandas way\n",
    "- Pyspark way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: We studied two ways to obtain arithmetic operation on a column in Pyspark DataFrame\n",
    "\n",
    "- Resource: https://stackoverflow.com/questions/41195378/what-is-the-most-efficient-way-in-pyspark-to-reduce-a-dataframe\n",
    "- RDD based\n",
    "- Function based (known as spark sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain the sum of age for Age column in Titanic (RDD Based)\n",
    "\n",
    "df.filter(df['Age'].isNotNull()).select(['Age']).rdd.map(lambda x: x[0]).reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain the sum of age for Age column in Titanic (Function Based or spark sql)\n",
    "from pyspark.sql.functions import mean, sum\n",
    "\n",
    "df.select(sum('Age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: For titanic, apply a function to each AGE value with the followings:\n",
    "\n",
    "- age = age - mean(age)\n",
    "- Create a new column or update the Age column with the above normalization is required \n",
    "- With RDD transformation, it is easy to have a new RDD of normalized age but return it back to `df` is needed also\n",
    "- To do this transformation and updating the `df` at the same time, we need User Defined Function (UDF) that will be introduced in the next session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "-  https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/5722190290795989/3865595167034368/8175309257345795/latest.html\n",
    "\n",
    "- https://gist.github.com/AlessandroChecco/c930a8b868342fa34b23a1f282dc3e88"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
