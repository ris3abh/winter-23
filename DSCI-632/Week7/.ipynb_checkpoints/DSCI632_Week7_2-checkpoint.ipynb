{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classifier in Pyspark\n",
    "\n",
    "- Use Pyspark ML for text classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"JAVA_HOME\"]='/usr/local/opt/openjdk@8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = spark.read.csv(\"spam.csv\", sep = \",\", inferSchema=False, header = True, encoding='latin1')\n",
    "df = spark.read.csv(\"SMSSpamCollection\", sep = \"\\t\", inferSchema=True, header = False)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = df.drop('_c2', '_c3', '_c4')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|status|             message|\n",
      "+------+--------------------+\n",
      "|   ham|Go until jurong p...|\n",
      "|   ham|Ok lar... Joking ...|\n",
      "|  spam|Free entry in 2 a...|\n",
      "|   ham|U dun say so earl...|\n",
      "|   ham|Nah I don't think...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = df.withColumnRenamed('v1', 'status').withColumnRenamed('v2', 'message')\n",
    "df = df.withColumnRenamed('_c0', 'status').withColumnRenamed('_c1', 'message')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  1.0|Go until jurong p...|\n",
      "|  1.0|Ok lar... Joking ...|\n",
      "|  0.0|Free entry in 2 a...|\n",
      "|  1.0|U dun say so earl...|\n",
      "|  1.0|Nah I don't think...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('temp')\n",
    "df = spark.sql('select case status when \"ham\" then 1.0  else 0 end as label, message from temp')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  747|\n",
      "|  1.0| 4827|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|             message|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar, joking,...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don, t, ...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|\n",
      "|  0.0|WINNER!! As a val...|[winner, as, a, v...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|\n",
      "|  1.0|I'm gonna be home...|[i, m, gonna, be,...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|\n",
      "|  0.0|URGENT! You have ...|[urgent, you, hav...|\n",
      "|  1.0|I've been searchi...|[i, ve, been, sea...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k, i, m, wat...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|\n",
      "|  1.0|Fine if thats th...|[fine, if, that, ...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import  RegexTokenizer\n",
    "tokenizer = RegexTokenizer(inputCol=\"message\", outputCol=\"words\", pattern='[^\\\\w]')\n",
    "wordsData = tokenizer.transform(df)\n",
    "wordsData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordsData = wordsData.limit(100)\n",
    "wordsData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply CountVectorizer\n",
    "\n",
    "- CountVectorizer converts the list of tokens above to vectors of token counts\n",
    "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|             message|               words|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|(8748,[7,52,60,61...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar, joking,...|(8748,[5,48,338,4...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|(8748,[1,3,7,17,2...|\n",
      "|  1.0|U dun say so earl...|[u, dun, say, so,...|(8748,[5,25,59,11...|\n",
      "|  1.0|Nah I don't think...|[nah, i, don, t, ...|(8748,[0,1,23,64,...|\n",
      "|  0.0|FreeMsg Hey there...|[freemsg, hey, th...|(8748,[0,1,2,6,11...|\n",
      "|  1.0|Even my brother i...|[even, my, brothe...|(8748,[1,8,9,10,2...|\n",
      "|  1.0|As per your reque...|[as, per, your, r...|(8748,[1,12,13,53...|\n",
      "|  0.0|WINNER!! As a val...|[winner, as, a, v...|(8748,[1,2,3,15,1...|\n",
      "|  0.0|Had your mobile 1...|[had, your, mobil...|(8748,[1,4,5,12,1...|\n",
      "|  1.0|I'm gonna be home...|[i, m, gonna, be,...|(8748,[0,1,6,23,2...|\n",
      "|  0.0|SIX chances to wi...|[six, chances, to...|(8748,[1,6,42,50,...|\n",
      "|  0.0|URGENT! You have ...|[urgent, you, hav...|(8748,[1,2,3,4,7,...|\n",
      "|  1.0|I've been searchi...|[i, ve, been, sea...|(8748,[0,1,2,3,4,...|\n",
      "|  1.0|I HAVE A DATE ON ...|[i, have, a, date...|(8748,[0,3,18,19,...|\n",
      "|  0.0|XXXMobileMovieClu...|[xxxmobilemoviecl...|(8748,[1,4,7,13,2...|\n",
      "|  1.0|Oh k...i'm watchi...|[oh, k, i, m, wat...|(8748,[0,28,98,11...|\n",
      "|  1.0|Eh u remember how...|[eh, u, remember,...|(8748,[0,5,20,45,...|\n",
      "|  1.0|Fine if thats th...|[fine, if, that, ...|(8748,[4,5,16,17,...|\n",
      "|  0.0|England v Macedon...|[england, v, mace...|(8748,[1,4,33,75,...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "model = count_vec.fit(wordsData)\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(8748,[7,52,60,61,69,92,127,138,150,343,472,654,742,877,1373,1413,1427,3000,7571,8201],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                       |\n",
      "|(8748,[5,48,338,475,1557,2113],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                                       |\n",
      "|(8748,[1,3,7,17,20,23,51,73,75,119,183,257,347,390,407,481,569,671,809,893,983,1104,1936,2089,2112,2386,2653,3372],[3.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|(8748,[5,25,59,119,153,157,248,381,3550],[2.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                 |\n",
      "|(8748,[0,1,23,64,80,112,116,223,470,489,977,1050,2266],[1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                   |\n",
      "|(8748,[0,1,2,6,11,12,17,21,40,46,48,58,61,71,78,91,93,99,113,114,120,132,139,215,342,370,415,780,983,1870,2199,4078,6775],[1.0,2.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(8748,[1,8,9,10,27,38,58,105,211,382,598,723,6058,7910],[1.0,1.0,2.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                              |\n",
      "|(8748,[1,12,13,53,74,113,125,235,245,402,607,846,1066,1097,1175,1634,1786,1974,2433,2537,2636],[1.0,1.0,3.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])                                                                           |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.select('features').show(8,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'to', 'you', 'a', 'the', 'u', 'and', 'in', 'is', 'me']\n"
     ]
    }
   ],
   "source": [
    "print(model.vocabulary[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As an example, 'to' is index 1 and appears 3 time in sentences 3 and 1 time in sentense 7\n",
    "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
    "\n",
    "\n",
    "Even my brother is not like to speak with me. They treat me like aids patent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(8748,[7,52,60,61...|\n",
      "|  1.0|(8748,[5,48,338,4...|\n",
      "|  0.0|(8748,[1,3,7,17,2...|\n",
      "|  1.0|(8748,[5,25,59,11...|\n",
      "|  1.0|(8748,[0,1,23,64,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData = featurizedData.select(['label', 'features'])\n",
    "featurizedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10  # set seed for reproducibility\n",
    "trainDF, testDF = featurizedData.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(8748,[0,1,2,3,6,...|\n",
      "|  0.0|(8748,[0,1,2,3,13...|\n",
      "|  0.0|(8748,[0,1,2,3,13...|\n",
      "|  0.0|(8748,[0,1,2,3,14...|\n",
      "|  0.0|(8748,[0,1,2,5,6,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4451"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "lr = LogisticRegression(maxIter = 10)\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, np.linspace(0.3, 0.01, 10)) \\\n",
    "    .addGrid(lr.elasticNetParam, np.linspace(0.3, 0.8, 6)) \\\n",
    "    .build()\n",
    "crossval_lr = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid_lr,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds= 5)  \n",
    "cvModel_lr = crossval_lr.fit(trainDF)\n",
    "best_model_lr = cvModel_lr.bestModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(8748,[0,1,2,3,6,...|[-0.4863393904709...|[0.38075629205915...|       1.0|\n",
      "|  0.0|(8748,[0,1,2,3,13...|[1.83750308503984...|[0.86265313398684...|       0.0|\n",
      "|  0.0|(8748,[0,1,2,3,13...|[1.83750308503984...|[0.86265313398684...|       0.0|\n",
      "|  0.0|(8748,[0,1,2,3,14...|[1.05195635570505...|[0.74115039618105...|       0.0|\n",
      "|  0.0|(8748,[0,1,2,5,6,...|[2.61536902487082...|[0.93184417792660...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_lr.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = cvModel_lr.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(8748,[0,1,2,3,6,...|[3.00633005917547...|[0.95285927988722...|       0.0|\n",
      "|  0.0|(8748,[0,1,2,3,13...|[1.83750308503984...|[0.86265313398684...|       0.0|\n",
      "|  0.0|(8748,[0,1,2,4,7,...|[1.13082750118948...|[0.75599157917591...|       0.0|\n",
      "|  0.0|(8748,[0,1,2,9,10...|[-0.0607815723814...|[0.48480928333143...|       1.0|\n",
      "|  0.0|(8748,[0,1,3,6,10...|[-0.2273395500029...|[0.44340863836306...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the probability columns, contains this tuple $(P_{spam}, P_{ham})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|   23|\n",
      "|  1.0|       1.0|  960|\n",
      "|  0.0|       0.0|  138|\n",
      "|  1.0|       0.0|    2|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.groupBy('label','prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23 + 960 + 138 + 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
