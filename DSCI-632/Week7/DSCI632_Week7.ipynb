{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Pyspark\n",
    "\n",
    "- Pyspark has two machine learning libraries:\n",
    "    \n",
    "    - mllib, mainly RDD based\n",
    "    - ml, mainly Pyspark DataFrame based\n",
    "    \n",
    "- Spark ML is the newer, scikit-learn inspired, machine learning library and is where new active development is taking place\n",
    "- The spark.ml is considered as the recommended package because with DataFrames the API is more versatile and flexible.\n",
    "- Name of columns for both mllib and ML is important in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('LinearReg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter).csv(\"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|radio|newspaper|sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionDataFrame = df.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[TV: string, radio: string, newspaper: string, sales: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TV='230.1', radio='37.8', newspaper='69.2', sales='22.1'),\n",
       " Row(TV='44.5', radio='39.3', newspaper='45.1', sales='10.4'),\n",
       " Row(TV='17.2', radio='45.9', newspaper='69.3', sales='9.3'),\n",
       " Row(TV='151.5', radio='41.3', newspaper='58.5', sales='18.5'),\n",
       " Row(TV='180.8', radio='10.8', newspaper='58.4', sales='12.9')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataFrame.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|radio|newspaper|sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionDataRDD = regressionDataFrame.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['230.1', '37.8', '69.2', '22.1'],\n",
       " ['44.5', '39.3', '45.1', '10.4'],\n",
       " ['17.2', '45.9', '69.3', '9.3'],\n",
       " ['151.5', '41.3', '58.5', '18.5'],\n",
       " ['180.8', '10.8', '58.4', '12.9']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled Points\n",
    "\n",
    "MLlib requires that our features be expressed with LabeledPoints. The required format for a labeled point is a tuple of the target value and a vector of predictors (features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "regressionDataLabelPoint = regressionDataRDD.map(lambda data : LabeledPoint(data[3], data[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressionDataLabelPoint.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[LabeledPoint(22.1, [230.1,37.8,69.2]),\n",
    " LabeledPoint(10.4, [44.5,39.3,45.1]),\n",
    " LabeledPoint(9.3, [17.2,45.9,69.3]),\n",
    " LabeledPoint(18.5, [151.5,41.3,58.5]),\n",
    " LabeledPoint(12.9, [180.8,10.8,58.4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionLabelPointSplit = regressionDataLabelPoint.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionLabelPointTrainData = regressionLabelPointSplit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(regressionLabelPointTrainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: We can transform Pyspark dataframe to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[230.1, 37.8, 69.2]</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[17.2, 45.9, 69.3]</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[151.5, 41.3, 58.5]</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[180.8, 10.8, 58.4]</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[57.5, 32.8, 23.5]</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              features  label\n",
       "0  [230.1, 37.8, 69.2]   22.1\n",
       "1   [17.2, 45.9, 69.3]    9.3\n",
       "2  [151.5, 41.3, 58.5]   18.5\n",
       "3  [180.8, 10.8, 58.4]   12.9\n",
       "4   [57.5, 32.8, 23.5]   11.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabelPointTrainData.toDF().toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([DenseVector([230.1, 37.8, 69.2]), DenseVector([17.2, 45.9, 69.3]),\n",
       "       DenseVector([151.5, 41.3, 58.5]), DenseVector([180.8, 10.8, 58.4]),\n",
       "       DenseVector([57.5, 32.8, 23.5]), DenseVector([120.2, 19.6, 11.6]),\n",
       "       DenseVector([8.6, 2.1, 1.0]), DenseVector([199.8, 2.6, 21.2]),\n",
       "       DenseVector([66.1, 5.8, 24.2]), DenseVector([204.1, 32.9, 46.0])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabelPointTrainData.toDF().toPandas()['features'].values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need an extra step here to have numpy array\n",
    "\n",
    "- http://blog.madhukaraphatak.com/spark-vector-to-numpy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionLabelPointTestData = regressionLabelPointSplit[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD as lrSGD\n",
    "\n",
    "ourModelWithLinearRegression  = lrSGD.train(data = regressionLabelPointTrainData, \n",
    "                                            iterations = 100, step = 0.0002, intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(weights=[0.05732977236215489,0.10086159549519522,0.052482565077522574], intercept=1.0021531334458886)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourModelWithLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0573, 0.1009, 0.0525])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourModelWithLinearRegression.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0021531334458886"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourModelWithLinearRegression.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Model Performance with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(10.4, [44.5,39.3,45.1]), LabeledPoint(7.2, [8.7,48.9,75.0])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabelPointTestData.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabelPointTestData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabelPointTrainData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|        features|label|\n",
      "+----------------+-----+\n",
      "|[44.5,39.3,45.1]| 10.4|\n",
      "| [8.7,48.9,75.0]|  7.2|\n",
      "+----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionLabelPointTestData.toDF().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "prediObserRDDin = regressionLabelPointTestData.\\\n",
    "map(lambda x: (float(ourModelWithLinearRegression.predict(x.features)),x.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.88415239151922, 10.4), (10.369246553525876, 7.2)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediObserRDDin.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.evaluation.RegressionMetrics at 0x7f31aca48880>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = RegressionMetrics(prediObserRDDin)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964421473548583"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.295759591568639"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- https://www.lucasallen.io/spark-dataframes-mllib-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
