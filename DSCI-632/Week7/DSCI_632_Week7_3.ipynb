{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"DataFramesAndMLLib\"\n",
    "SPARK_URL = \"local[*]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal.length|sepal.width|petal.length|petal.width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.withColumnRenamed('sepal.length', 'sepal_length')\n",
    "iris = iris.withColumnRenamed('sepal.width', 'sepal_width')\n",
    "iris = iris.withColumnRenamed('petal.length', 'petal_length')\n",
    "iris = iris.withColumnRenamed('petal.width', 'petal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'variety']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [x for x in iris.columns if x != 'variety']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "\n",
    "iris_features = assembler.transform(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|         features|\n",
      "+------------+-----------+------------+-----------+-------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|[5.0,3.6,1.4,0.2]|\n",
      "+------------+-----------+------------+-----------+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This step is the same as label encoder in sklearn\n",
    "indexer = StringIndexer(inputCol='variety', outputCol='label')\n",
    "index_model = indexer.fit(iris_features)\n",
    "iris_input = index_model.transform(iris_features).select(\"features\", \"label\")\n",
    "iris_input.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 40\n"
     ]
    }
   ],
   "source": [
    "train, test = iris_input.randomSplit([0.7, 0.3], seed = 1)\n",
    "\n",
    "print(train.count(), test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "rfModel = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------+-------------+----------+\n",
      "|         features|label| rawPrediction|  probability|prediction|\n",
      "+-----------------+-----+--------------+-------------+----------+\n",
      "|[4.5,2.3,1.3,0.3]|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.8,3.1,1.6,0.2]|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.8,3.4,1.6,0.2]|  0.0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|[4.8,3.4,1.9,0.2]|  0.0|[16.0,4.0,0.0]|[0.8,0.2,0.0]|       0.0|\n",
      "+-----------------+-----+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_rdd = prediction.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "prediction_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "metrics = MulticlassMetrics(prediction_rdd)\n",
    "metrics.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Dataset\n",
    "\n",
    "- Apply linear regression to the following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insurance.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many unique region do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|   region|\n",
      "+---------+\n",
      "|northwest|\n",
      "|southeast|\n",
      "|northeast|\n",
      "|southwest|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insurance.select('region').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|region_index|\n",
      "+---+------+------+--------+------+---------+-----------+------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|         2.0|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|         0.0|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|         0.0|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|         1.0|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|         1.0|\n",
      "+---+------+------+--------+------+---------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "string_index = StringIndexer(inputCol='region', outputCol='region_index').fit(insurance)\n",
    "\n",
    "insurance_with_label_encoder = string_index.transform(insurance)\n",
    "insurance_with_label_encoder.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------+-------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|region_index|   region_num|\n",
      "+---+------+------+--------+------+---------+-----------+------------+-------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|         2.0|(3,[2],[1.0])|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|         0.0|(3,[0],[1.0])|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|         0.0|(3,[0],[1.0])|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|         1.0|(3,[1],[1.0])|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|         1.0|(3,[1],[1.0])|\n",
      "+---+------+------+--------+------+---------+-----------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "one_hot_index = OneHotEncoder(inputCols=[\"region_index\"], outputCols=[\"region_num\"]).fit(insurance_with_label_encoder)\n",
    "insurance_with_label_encoder_onehot = one_hot_index.transform(insurance_with_label_encoder)\n",
    "insurance_with_label_encoder_onehot.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>region_index</th>\n",
       "      <th>region_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges  region_index  \\\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400           2.0   \n",
       "1   18    male  33.770         1     no  southeast   1725.55230           0.0   \n",
       "2   28    male  33.000         3     no  southeast   4449.46200           0.0   \n",
       "3   33    male  22.705         0     no  northwest  21984.47061           1.0   \n",
       "4   32    male  28.880         0     no  northwest   3866.85520           1.0   \n",
       "\n",
       "        region_num  \n",
       "0  (0.0, 0.0, 1.0)  \n",
       "1  (1.0, 0.0, 0.0)  \n",
       "2  (1.0, 0.0, 0.0)  \n",
       "3  (0.0, 1.0, 0.0)  \n",
       "4  (0.0, 1.0, 0.0)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to understand what region_num values represent\n",
    "insurance_with_label_encoder_onehot.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instead of doing all the machine learning pre-processing steps one by one\n",
    "\n",
    "- use pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+------------+---------+------------+-------------+--------------------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|smoker_index|sex_index|region_index|   region_num|            features|\n",
      "+---+------+------+--------+------+---------+-----------+------------+---------+------------+-------------+--------------------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|         1.0|      1.0|         2.0|(3,[2],[1.0])|[19.0,27.9,0.0,1....|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|         0.0|      0.0|         0.0|(3,[0],[1.0])|(8,[0,1,2,5],[18....|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|         0.0|      0.0|         0.0|(3,[0],[1.0])|(8,[0,1,2,5],[28....|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|         0.0|      0.0|         1.0|(3,[1],[1.0])|(8,[0,1,6],[33.0,...|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|         0.0|      0.0|         1.0|(3,[1],[1.0])|(8,[0,1,6],[32.0,...|\n",
      "+---+------+------+--------+------+---------+-----------+------------+---------+------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "cols = [\"smoker\", \"sex\", \"region\"]\n",
    "stages = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(insurance) for column in cols]\n",
    "stages.append(OneHotEncoder(inputCols=[\"region_index\"], outputCols=[\"region_num\"]))\n",
    "\n",
    "feature_cols = ['age', 'bmi', 'children', 'smoker_index', 'sex_index', 'region_num']\n",
    "stages.append(VectorAssembler(inputCols=feature_cols, outputCol='features'))\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "insurance_transformed = pipeline.fit(insurance).transform(insurance)\n",
    "\n",
    "insurance_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [256.85635253734966,339.1934536108323,475.50054514913035,23848.534541912828,131.3143593950504,-1035.022049387815,-352.96389942466794,-960.050991300835]\n",
      "Intercept: -12069.852935562118\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='charges', maxIter=10)\n",
    "lr_model = lr.fit(insurance_transformed)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we have 8 Coefficients here?\n",
    "## What we have missed for insurance dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
